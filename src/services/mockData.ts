import type {
  AgentResponse,
  Conversation,
  MetricsAnalysisResponse,
} from '../types/chatbot'

// Mock ì‘ë‹µ ìƒì„± í•¨ìˆ˜
const createMockResponse = (message: string): AgentResponse => {
  // ì¸ì‚¬ì´íŠ¸/ëŒ€ì‹œë³´ë“œ ì „ìš© ì‘ë‹µë“¤
  const dashboardResponses = [
    `ğŸ“Š **í˜„ì¬ ëŒ€ì‹œë³´ë“œ ìš”ì•½**

**ì„±ëŠ¥ ì§€í‘œ:**
â€¢ í‰ê·  ì‘ë‹µì‹œê°„: 280ms (ëª©í‘œ: <300ms) âœ…
â€¢ 95í¼ì„¼íƒ€ì¼: 950ms (ê°œì„  í•„ìš”)
â€¢ ì˜¤ë¥˜ìœ¨: 2.5% (ì •ìƒ ë²”ìœ„)
â€¢ ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 100ê±´

**ì‚¬ìš©ëŸ‰ í˜„í™©:**
â€¢ ì´ ëŒ€í™”ìˆ˜: 240ê°œ (24ì‹œê°„)
â€¢ í‰ê·  ë©”ì‹œì§€: 6.5ê°œ/ëŒ€í™”
â€¢ ì‚¬ìš©ì ë§Œì¡±ë„: 8.9/10 (ìš°ìˆ˜)

**ê¶Œì¥ì‚¬í•­:** í”¼í¬ì‹œê°„ ì‘ë‹µì‹œê°„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.`,

    `ğŸ’¡ **ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë¶„ì„**

**ì„±ëŠ¥ íŠ¸ë Œë“œ:**
â€¢ ì‘ë‹µì‹œê°„ í‰ê·  280msë¡œ ì•ˆì •ì  ìœ ì§€
â€¢ í”¼í¬íƒ€ì„(14-16ì‹œ) íŠ¸ë˜í”½ 50% ì§‘ì¤‘

**ì‚¬ìš© íŒ¨í„´:**
â€¢ ì˜¤í›„ ì‹œê°„ëŒ€ ì‚¬ìš©ëŸ‰ 50% ì§‘ì¤‘
â€¢ ì±„íŒ… ê¸°ëŠ¥ì´ ì „ì²´ ì‚¬ìš©ì˜ 70% ì°¨ì§€
â€¢ í‰ê·  ëŒ€í™” ê¸¸ì´ 6.5ë©”ì‹œì§€ë¡œ ì ì • ìˆ˜ì¤€

**ê°œì„  í¬ì¸íŠ¸:**
â€¢ 95í¼ì„¼íƒ€ì¼ ì‘ë‹µì‹œê°„ 950ms ê°œì„  í•„ìš”
â€¢ ì˜¤ë¥˜ìœ¨ 2.5%ë¥¼ 2% ì´í•˜ë¡œ ê°ì†Œ ëª©í‘œ`,

    `ğŸ“ˆ **ì‚¬ìš©ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸**

**ëŒ€í™” í†µê³„:**
â€¢ ì´ ëŒ€í™”ìˆ˜: 240ê°œ (24ì‹œê°„)
â€¢ í‰ê·  ëŒ€í™” ê¸¸ì´: 6.5ë©”ì‹œì§€  
â€¢ ì„±ê³µë¥ : 95.8% (2300/2400)

**í’ˆì§ˆ ì§€í‘œ:**
â€¢ í‰ê·  í’ˆì§ˆì ìˆ˜: 8.5/10
â€¢ ì‚¬ìš©ì ë§Œì¡±ë„: 8.9/10
â€¢ í† í° ì‚¬ìš©ëŸ‰: 24,800ê°œ

**ì„±ì¥ ì¶”ì„¸:** ì•ˆì •ì ì¸ ì‚¬ìš© íŒ¨í„´ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.`,

    `ğŸ” **ì‹œìŠ¤í…œ í˜„í™© ì²´í¬**

**ì•ˆì •ì„±:**
â€¢ ê°€ë™ì‹œê°„: 99.6% (24ì‹œê°„ ê¸°ì¤€)
â€¢ ì‹œìŠ¤í…œ ìƒíƒœ: ì–‘í˜¸ (Good)
â€¢ í™œì„± ì—°ê²°: 100ê°œ

**ì„±ëŠ¥ í˜„í™©:**
â€¢ í‰ê·  ì‘ë‹µì‹œê°„: 280ms
â€¢ ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 100ê±´
â€¢ ì˜¤ë¥˜ìœ¨: 2.5%

**ìƒíƒœ:** ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.`
  ]

  // ëŒ€ì‹œë³´ë“œ ìš”ì•½ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
  const isDashboardQuery = message.toLowerCase().includes('ëŒ€ì‹œë³´ë“œ') ||
                          message.toLowerCase().includes('ìš”ì•½') ||
                          message.toLowerCase().includes('í˜„í™©') ||
                          message.toLowerCase().includes('ìƒíƒœ') ||
                          message.toLowerCase().includes('ì§€í‘œ')

  // ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬  
  const isInsightQuery = message.toLowerCase().includes('ì¸ì‚¬ì´íŠ¸') ||
                        message.toLowerCase().includes('ë¶„ì„') ||
                        message.toLowerCase().includes('ë³´ê³ ì„œ') ||
                        message.toLowerCase().includes('ê°œì„ ') ||
                        message.toLowerCase().includes('ì œì•ˆ') ||
                        message.toLowerCase().includes('ìµœì í™”')

  const isValidQuery = isDashboardQuery || isInsightQuery

  let content
  if (isDashboardQuery) {
    // ëŒ€ì‹œë³´ë“œ ê´€ë ¨ ì‘ë‹µ (ì²« ë²ˆì§¸ì™€ ë„¤ ë²ˆì§¸ ì‘ë‹µ)
    const dashboardSpecific = [dashboardResponses[0], dashboardResponses[3]]
    content = dashboardSpecific[Math.floor(Math.random() * dashboardSpecific.length)]
  } else if (isInsightQuery) {
    // ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ê´€ë ¨ ì‘ë‹µ (ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸ ì‘ë‹µ)
    const insightSpecific = [dashboardResponses[1], dashboardResponses[2]]
    content = insightSpecific[Math.floor(Math.random() * insightSpecific.length)]
  } else {
    content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” **ëŒ€ì‹œë³´ë“œ ìš”ì•½**ê³¼ **ì¸ì‚¬ì´íŠ¸ ë¶„ì„** ë‘ ê°€ì§€ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  }

  return {
    content,
    conversationId: `conv-${Date.now()}`,
    timestamp: new Date().toISOString(),
    isStreaming: false,
    sources: [],
    metadata: {
      responseTime: "150ms",
      toolsUsed: isValidQuery ? ["dashboard_analyzer", "metrics_monitor", "insight_generator"] : ["scope_filter"]
    },
    status: "SUCCESS"
  }
}

const createMockMetrics = (): MetricsAnalysisResponse => ({
  userId: "user-123",
  generatedAt: new Date().toISOString(),
  timeRange: "24 hours",
  performance: {
    avgResponseTime: 280,
    p95ResponseTime: 950,
    errorRate: 0.025,
    totalRequests: 2400,
    throughputPerHour: 100
  },
  usage: {
    totalConversations: 240,
    avgMessagesPerConversation: 6.5,
    avgMessageLength: 95,
    totalTokensUsed: 24800,
    featureUsage: {
      chat: 1680,
      streaming: 432,
      systemPrompt: 168,
      metrics: 120
    },
    timeDistribution: {
      morning: 25.0,
      afternoon: 50.0,
      evening: 25.0
    }
  },
  quality: {
    avgQualityScore: 8.5,
    userSatisfactionScore: 8.9,
    successfulInteractions: 2300,
    failedInteractions: 100,
    qualityByFeature: {
      chat: 8.5,
      streaming: 8.1,
      systemPrompt: 8.8,
      metrics: 8.7
    }
  },
  insights: [
    {
      type: "performance",
      title: "ì‘ë‹µ ì‹œê°„ ìµœì í™” í•„ìš”",
      description: "í”¼í¬ ì‹œê°„ëŒ€ ì‘ë‹µ ì‹œê°„ì´ í‰ê· ë³´ë‹¤ 40% ë†’ìŒ",
      severity: "warning",
      data: { peakHours: ["14:00-16:00", "20:00-22:00"] },
      recommendation: "ìºì‹± ì „ëµ ê²€í†  ë° ì¸í”„ë¼ ìŠ¤ì¼€ì¼ë§ ê³ ë ¤"
    },
    {
      type: "usage",
      title: "ì‚¬ìš©ëŸ‰ ì¦ê°€ ì¶”ì„¸",
      description: "ì§€ë‚œ ì£¼ ëŒ€ë¹„ ëŒ€í™”ìˆ˜ê°€ 25% ì¦ê°€",
      severity: "info",
      data: { growthRate: 0.25 },
      recommendation: "ì„œë²„ ìš©ëŸ‰ í™•ì¥ ê³„íš ìˆ˜ë¦½"
    },
    {
      type: "quality",
      title: "ë†’ì€ ì‚¬ìš©ì ë§Œì¡±ë„",
      description: "ì‚¬ìš©ì ë§Œì¡±ë„ê°€ 9.2ì ìœ¼ë¡œ ë§¤ìš° ë†’ìŒ",
      severity: "info",
      data: { satisfactionScore: 9.2 },
      recommendation: "í˜„ì¬ ì„œë¹„ìŠ¤ í’ˆì§ˆ ìœ ì§€"
    }
  ],
  rawData: {
    dailyStats: [
      { date: "2024-01-15", requests: 120, avgResponseTime: 230 },
      { date: "2024-01-16", requests: 135, avgResponseTime: 245 },
      { date: "2024-01-17", requests: 150, avgResponseTime: 260 }
    ]
  }
})

const createMockConversations = (): Conversation[] => [
  {
    id: "conv-1",
    userId: "user-123",
    title: "ì„œë²„ ìƒíƒœ í™•ì¸",
    summary: "ì‚¬ìš©ìê°€ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ëª¨ë‹ˆí„°ë§ ì„¤ì •ì— ëŒ€í•´ ë¬¸ì˜í•¨",
    createdAt: "2024-01-15T09:00:00Z",
    lastActivity: "2024-01-15T10:30:00Z",
    messageCount: 5,
    isActive: true
  },
  {
    id: "conv-2",
    userId: "user-123",
    title: "ë©”íŠ¸ë¦­ ë¶„ì„ ìš”ì²­",
    summary: "ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ì‚¬ìš©ëŸ‰ ë°ì´í„°ì— ëŒ€í•œ ë¶„ì„ ìš”ì²­",
    createdAt: "2024-01-14T14:20:00Z",
    lastActivity: "2024-01-14T15:45:00Z",
    messageCount: 8,
    isActive: false
  },
  {
    id: "conv-3",
    userId: "user-123",
    title: "ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸",
    summary: "ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸ì™€ ìµœì í™” ë°©ì•ˆì— ëŒ€í•œ ë…¼ì˜",
    createdAt: "2024-01-13T11:10:00Z",
    lastActivity: "2024-01-13T12:00:00Z",
    messageCount: 3,
    isActive: true
  }
]

const mockData = {
  createMockResponse,
  createMockMetrics,
  createMockConversations,
  
  // ì¶”ê°€ Mock ë°ì´í„°
  health: {
    status: "UP",
    service: "AI Agent",
    timestamp: Date.now(),
    activeConversations: 25
  },
  
  performanceMetrics: {
    cpu: { usage: 45.2, cores: 8 },
    memory: { used: 6.8, total: 16.0, percentage: 42.5 },
    network: { inbound: 125.3, outbound: 98.7 },
    disk: { used: 120.5, total: 500.0, percentage: 24.1 }
  },
  
  usageMetrics: {
    dailyActiveUsers: 156,
    totalSessions: 342,
    avgSessionDuration: 15.5,
    bounceRate: 12.3
  },
  
  qualityMetrics: {
    responseAccuracy: 94.5,
    userRating: 4.6,
    completionRate: 88.9,
    escalationRate: 5.2
  },
  
  realtimeMetrics: {
    currentLoad: 67.8,
    activeConnections: 234,
    requestsPerSecond: 12.5,
    errorCount: 3
  },
  
  systemMetrics: {
    uptime: 2592000, // 30 days in seconds
    version: "1.2.3",
    lastRestart: "2024-01-01T00:00:00Z",
    health: "optimal"
  },
  
  topUsers: [
    { userId: "user-001", requests: 456, lastSeen: "2024-01-17T10:00:00Z" },
    { userId: "user-002", requests: 389, lastSeen: "2024-01-17T09:30:00Z" },
    { userId: "user-003", requests: 312, lastSeen: "2024-01-17T08:45:00Z" },
    { userId: "user-004", requests: 287, lastSeen: "2024-01-17T07:20:00Z" },
    { userId: "user-005", requests: 234, lastSeen: "2024-01-17T06:15:00Z" }
  ],
  
  trends: {
    "api.response_time": [
      { timestamp: "2024-01-15T00:00:00Z", value: 230 },
      { timestamp: "2024-01-16T00:00:00Z", value: 245 },
      { timestamp: "2024-01-17T00:00:00Z", value: 260 },
      { timestamp: "2024-01-18T00:00:00Z", value: 255 },
      { timestamp: "2024-01-19T00:00:00Z", value: 240 }
    ]
  }
}

export default mockData