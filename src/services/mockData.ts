import type {
  AgentResponse,
  Conversation,
  MetricsAnalysisResponse,
} from '../types/chatbot'

// Mock ì‘ë‹µ ìƒì„± í•¨ìˆ˜
const createMockResponse = (message: string): AgentResponse => {
  // ì¸ì‚¬ì´íŠ¸/ëŒ€ì‹œë³´ë“œ ì „ìš© ì‘ë‹µë“¤
  const dashboardResponses = [
    `ğŸ“Š **í˜„ì¬ ëŒ€ì‹œë³´ë“œ ìš”ì•½**

**ì„±ëŠ¥ ì§€í‘œ:**
â€¢ í‰ê·  ì‘ë‹µì‹œê°„: 245.5ms (ëª©í‘œ: <300ms) âœ…
â€¢ 95í¼ì„¼íƒ€ì¼: 850.2ms (ì£¼ì˜ í•„ìš”)
â€¢ ì˜¤ë¥˜ìœ¨: 2.1% (ì •ìƒ ë²”ìœ„)

**ì‚¬ìš©ëŸ‰ í˜„í™©:**
â€¢ í™œì„± ëŒ€í™”: 128ê°œ (ì „ì¼ ëŒ€ë¹„ +15%)
â€¢ ì‚¬ìš©ì ë§Œì¡±ë„: 9.2/10 (ìš°ìˆ˜)

**ê¶Œì¥ì‚¬í•­:** í”¼í¬ì‹œê°„ ì„±ëŠ¥ ìµœì í™” ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.`,

    `ğŸ’¡ **ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë¶„ì„**

**ì„±ëŠ¥ íŠ¸ë Œë“œ:**
â€¢ ì‘ë‹µì‹œê°„ì´ ìµœê·¼ ì¼ì£¼ì¼ê°„ 12% ê°œì„ 
â€¢ í”¼í¬íƒ€ì„(14-16ì‹œ) ë¶€í•˜ ì§‘ì¤‘ í˜„ìƒ

**ì‚¬ìš© íŒ¨í„´:**
â€¢ ì˜¤í›„ ì‹œê°„ëŒ€ ì‚¬ìš©ëŸ‰ 45.2% ì§‘ì¤‘
â€¢ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ ì‚¬ìš©ë¥  20% ì¦ê°€

**ê°œì„  í¬ì¸íŠ¸:**
â€¢ ìºì‹± ì „ëµ ìµœì í™”ë¡œ ì‘ë‹µì‹œê°„ ë‹¨ì¶• ê°€ëŠ¥
â€¢ ë¡œë“œë°¸ëŸ°ì‹±ìœ¼ë¡œ í”¼í¬íƒ€ì„ ì•ˆì •ì„± í–¥ìƒ`,

    `ğŸ“ˆ **ì‚¬ìš©ëŸ‰ ë¶„ì„ ë¦¬í¬íŠ¸**

**ëŒ€í™” í†µê³„:**
â€¢ ì´ ëŒ€í™”ìˆ˜: 128ê°œ (ì¼í‰ê·  8.5íšŒ)
â€¢ í‰ê·  ëŒ€í™” ê¸¸ì´: 8.5ë©”ì‹œì§€
â€¢ ì™„ë£Œìœ¨: 88.9%

**í’ˆì§ˆ ì§€í‘œ:**
â€¢ ì •í™•ë„: 94.5%
â€¢ ì‚¬ìš©ì í‰ì : 4.6/5
â€¢ ì¬ì‚¬ìš©ë¥ : 87.3%

**ì„±ì¥ ì¶”ì„¸:** ì£¼ê°„ ì‚¬ìš©ëŸ‰ 25% ì¦ê°€ë¡œ ê¸ì •ì  ì„±ì¥ì„¸ì…ë‹ˆë‹¤.`,

    `ğŸ” **ì‹œìŠ¤í…œ í˜„í™© ì²´í¬**

**ì•ˆì •ì„±:**
â€¢ ê°€ë™ì‹œê°„: 99.8% (30ì¼ ê¸°ì¤€)
â€¢ ì‹œìŠ¤í…œ ìƒíƒœ: ìµœì  (Optimal)
â€¢ í™œì„± ì—°ê²°: 234ê°œ

**ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ :**
â€¢ CPU: 45.2% (ì—¬ìœ )
â€¢ ë©”ëª¨ë¦¬: 42.5% (ì •ìƒ)
â€¢ ë„¤íŠ¸ì›Œí¬: 125.3MB/s ì¸ë°”ìš´ë“œ

**ìƒíƒœ:** ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤.`
  ]

  // ëŒ€ì‹œë³´ë“œ ìš”ì•½ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬
  const isDashboardQuery = message.toLowerCase().includes('ëŒ€ì‹œë³´ë“œ') ||
                          message.toLowerCase().includes('ìš”ì•½') ||
                          message.toLowerCase().includes('í˜„í™©') ||
                          message.toLowerCase().includes('ìƒíƒœ') ||
                          message.toLowerCase().includes('ì§€í‘œ')

  // ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ê´€ë ¨ í‚¤ì›Œë“œ ì²´í¬  
  const isInsightQuery = message.toLowerCase().includes('ì¸ì‚¬ì´íŠ¸') ||
                        message.toLowerCase().includes('ë¶„ì„') ||
                        message.toLowerCase().includes('ë³´ê³ ì„œ') ||
                        message.toLowerCase().includes('ê°œì„ ') ||
                        message.toLowerCase().includes('ì œì•ˆ') ||
                        message.toLowerCase().includes('ìµœì í™”')

  const isValidQuery = isDashboardQuery || isInsightQuery

  let content
  if (isDashboardQuery) {
    // ëŒ€ì‹œë³´ë“œ ê´€ë ¨ ì‘ë‹µ (ì²« ë²ˆì§¸ì™€ ë„¤ ë²ˆì§¸ ì‘ë‹µ)
    const dashboardSpecific = [dashboardResponses[0], dashboardResponses[3]]
    content = dashboardSpecific[Math.floor(Math.random() * dashboardSpecific.length)]
  } else if (isInsightQuery) {
    // ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ê´€ë ¨ ì‘ë‹µ (ë‘ ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸ ì‘ë‹µ)
    const insightSpecific = [dashboardResponses[1], dashboardResponses[2]]
    content = insightSpecific[Math.floor(Math.random() * insightSpecific.length)]
  } else {
    content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” **ëŒ€ì‹œë³´ë“œ ìš”ì•½**ê³¼ **ì¸ì‚¬ì´íŠ¸ ë¶„ì„** ë‘ ê°€ì§€ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
  }

  return {
    content,
    conversationId: `conv-${Date.now()}`,
    timestamp: new Date().toISOString(),
    isStreaming: false,
    sources: [],
    metadata: {
      responseTime: "150ms",
      toolsUsed: isValidQuery ? ["dashboard_analyzer", "metrics_monitor", "insight_generator"] : ["scope_filter"]
    },
    status: "SUCCESS"
  }
}

const createMockMetrics = (): MetricsAnalysisResponse => ({
  userId: "user-123",
  generatedAt: new Date().toISOString(),
  timeRange: "24 hours",
  performance: {
    avgResponseTime: 245.5,
    p95ResponseTime: 850.2,
    errorRate: 0.021,
    totalRequests: 1205,
    throughputPerHour: 50.2
  },
  usage: {
    totalConversations: 128,
    avgMessagesPerConversation: 8.5,
    avgMessageLength: 125.3,
    totalTokensUsed: 15420,
    featureUsage: {
      chat: 850,
      streaming: 245,
      systemPrompt: 110,
      metrics: 95
    },
    timeDistribution: {
      morning: 30.5,
      afternoon: 45.2,
      evening: 24.3
    }
  },
  quality: {
    avgQualityScore: 8.7,
    userSatisfactionScore: 9.2,
    successfulInteractions: 1180,
    failedInteractions: 25,
    qualityByFeature: {
      chat: 8.7,
      streaming: 8.2,
      systemPrompt: 9.1,
      metrics: 8.9
    }
  },
  insights: [
    {
      type: "performance",
      title: "ì‘ë‹µ ì‹œê°„ ìµœì í™” í•„ìš”",
      description: "í”¼í¬ ì‹œê°„ëŒ€ ì‘ë‹µ ì‹œê°„ì´ í‰ê· ë³´ë‹¤ 40% ë†’ìŒ",
      severity: "warning",
      data: { peakHours: ["14:00-16:00", "20:00-22:00"] },
      recommendation: "ìºì‹± ì „ëµ ê²€í†  ë° ì¸í”„ë¼ ìŠ¤ì¼€ì¼ë§ ê³ ë ¤"
    },
    {
      type: "usage",
      title: "ì‚¬ìš©ëŸ‰ ì¦ê°€ ì¶”ì„¸",
      description: "ì§€ë‚œ ì£¼ ëŒ€ë¹„ ëŒ€í™”ìˆ˜ê°€ 25% ì¦ê°€",
      severity: "info",
      data: { growthRate: 0.25 },
      recommendation: "ì„œë²„ ìš©ëŸ‰ í™•ì¥ ê³„íš ìˆ˜ë¦½"
    },
    {
      type: "quality",
      title: "ë†’ì€ ì‚¬ìš©ì ë§Œì¡±ë„",
      description: "ì‚¬ìš©ì ë§Œì¡±ë„ê°€ 9.2ì ìœ¼ë¡œ ë§¤ìš° ë†’ìŒ",
      severity: "info",
      data: { satisfactionScore: 9.2 },
      recommendation: "í˜„ì¬ ì„œë¹„ìŠ¤ í’ˆì§ˆ ìœ ì§€"
    }
  ],
  rawData: {
    dailyStats: [
      { date: "2024-01-15", requests: 120, avgResponseTime: 230 },
      { date: "2024-01-16", requests: 135, avgResponseTime: 245 },
      { date: "2024-01-17", requests: 150, avgResponseTime: 260 }
    ]
  }
})

const createMockConversations = (): Conversation[] => [
  {
    id: "conv-1",
    userId: "user-123",
    title: "ì„œë²„ ìƒíƒœ í™•ì¸",
    summary: "ì‚¬ìš©ìê°€ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ëª¨ë‹ˆí„°ë§ ì„¤ì •ì— ëŒ€í•´ ë¬¸ì˜í•¨",
    createdAt: "2024-01-15T09:00:00Z",
    lastActivity: "2024-01-15T10:30:00Z",
    messageCount: 5,
    isActive: true
  },
  {
    id: "conv-2",
    userId: "user-123",
    title: "ë©”íŠ¸ë¦­ ë¶„ì„ ìš”ì²­",
    summary: "ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ì‚¬ìš©ëŸ‰ ë°ì´í„°ì— ëŒ€í•œ ë¶„ì„ ìš”ì²­",
    createdAt: "2024-01-14T14:20:00Z",
    lastActivity: "2024-01-14T15:45:00Z",
    messageCount: 8,
    isActive: false
  },
  {
    id: "conv-3",
    userId: "user-123",
    title: "ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸",
    summary: "ì‹œìŠ¤í…œ ì¸ì‚¬ì´íŠ¸ì™€ ìµœì í™” ë°©ì•ˆì— ëŒ€í•œ ë…¼ì˜",
    createdAt: "2024-01-13T11:10:00Z",
    lastActivity: "2024-01-13T12:00:00Z",
    messageCount: 3,
    isActive: true
  }
]

const mockData = {
  createMockResponse,
  createMockMetrics,
  createMockConversations,
  
  // ì¶”ê°€ Mock ë°ì´í„°
  health: {
    status: "UP",
    service: "AI Agent",
    timestamp: Date.now(),
    activeConversations: 25
  },
  
  performanceMetrics: {
    cpu: { usage: 45.2, cores: 8 },
    memory: { used: 6.8, total: 16.0, percentage: 42.5 },
    network: { inbound: 125.3, outbound: 98.7 },
    disk: { used: 120.5, total: 500.0, percentage: 24.1 }
  },
  
  usageMetrics: {
    dailyActiveUsers: 156,
    totalSessions: 342,
    avgSessionDuration: 15.5,
    bounceRate: 12.3
  },
  
  qualityMetrics: {
    responseAccuracy: 94.5,
    userRating: 4.6,
    completionRate: 88.9,
    escalationRate: 5.2
  },
  
  realtimeMetrics: {
    currentLoad: 67.8,
    activeConnections: 234,
    requestsPerSecond: 12.5,
    errorCount: 3
  },
  
  systemMetrics: {
    uptime: 2592000, // 30 days in seconds
    version: "1.2.3",
    lastRestart: "2024-01-01T00:00:00Z",
    health: "optimal"
  },
  
  topUsers: [
    { userId: "user-001", requests: 456, lastSeen: "2024-01-17T10:00:00Z" },
    { userId: "user-002", requests: 389, lastSeen: "2024-01-17T09:30:00Z" },
    { userId: "user-003", requests: 312, lastSeen: "2024-01-17T08:45:00Z" },
    { userId: "user-004", requests: 287, lastSeen: "2024-01-17T07:20:00Z" },
    { userId: "user-005", requests: 234, lastSeen: "2024-01-17T06:15:00Z" }
  ],
  
  trends: {
    "api.response_time": [
      { timestamp: "2024-01-15T00:00:00Z", value: 230 },
      { timestamp: "2024-01-16T00:00:00Z", value: 245 },
      { timestamp: "2024-01-17T00:00:00Z", value: 260 },
      { timestamp: "2024-01-18T00:00:00Z", value: 255 },
      { timestamp: "2024-01-19T00:00:00Z", value: 240 }
    ]
  }
}

export default mockData